{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:37:57.584258Z",
     "start_time": "2020-06-04T17:37:57.570148Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:14:28.307543Z",
     "start_time": "2020-06-04T19:13:38.060445Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'price open'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price open'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-25156ee6f5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-418467d7d7cf>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(company, tweets, resamp)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-418467d7d7cf>\u001b[0m in \u001b[0;36mclean_frame\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# filling times with no trades with previous prices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price high'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ffill'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price open'"
     ]
    }
   ],
   "source": [
    "stocks = get_data('./datasets/Russia Site/cleaned/', 'date_time')\n",
    "twits = get_data('./datasets/twitters/withsent/', 'date')\n",
    "\n",
    "counter = 0\n",
    "for company in stocks.keys():\n",
    "    process(stocks[company], twits[company], 's')\n",
    "    process(stocks[company], twits[company], 'min')\n",
    "    counter += 1\n",
    "    print(f'finished processing {company}. {counter}/{len(stocks.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:13:25.616587Z",
     "start_time": "2020-06-04T19:13:25.595718Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(company, tweets, resamp):\n",
    "    #resample\n",
    "    stock = company.drop(columns=['date', 'time']).copy()\n",
    "    twit = tweets[['vader_sentiment']].copy() # only care about this column\n",
    "    \n",
    "    stock['mean_price'] = stock['price']\n",
    "    stock = stock.resample(resamp).agg({'vol' : 'sum', 'price' : 'ohlc', 'mean_price' : 'mean'})\n",
    "    twit = twit.resample(resamp).mean()\n",
    "    \n",
    "    # ewm tweet score\n",
    "    hrs = 18 # amount of time to average\n",
    "    if resamp == 's':\n",
    "        span = 3600*hrs #hours in seconds.  \n",
    "    elif resamp == 'm':\n",
    "        span = 60*hrs #hours in minutes\n",
    "    else: span = hrs\n",
    "    # ewm tweet score\n",
    "    twit['sent_mean'] = twit.ewm(span).mean() #weighed mean\n",
    "    twit.drop(columns='vader_sentiment', inplace=True)\n",
    "    \n",
    "    # cleaning cols up before merge\n",
    "    stock.columns = [' '.join(col).strip() for col in stock.columns.values]\n",
    "    stock.rename(columns={'vol vol' : 'vol', 'mean_price mean_price' : 'mean_price'}, inplace=True)\n",
    "    \n",
    "    # Merge\n",
    "    df = pd.merge(stock, twit, left_index=True, right_index=True, how='left')\n",
    "    df = remove_closed(df)\n",
    "    df = clean_frame(df)\n",
    "    \n",
    "    # export\n",
    "    df['ticker'] = company\n",
    "    df.to_csv(f'./datasets/dow_clean/{resamp}/{company}.csv', index=True)\n",
    "\n",
    "def clean_frame(df):\n",
    "    # Fill NaNs and pct changes\n",
    "    # forward fill NAs in price\n",
    "    df['price high'].fillna(method='ffill', inplace=True)\n",
    "    df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "    df['vol'].fillna(0, inplace=True)\n",
    "\n",
    "    intervals = [1, 2, 3, 4, 5, 10, 15, 30, 60]\n",
    "    for i in intervals:\n",
    "        df[f'high_px_{i}'] = df['price high'].pct_change(i)\n",
    "        df[f'mean_px_{i}'] = df['mean_price'].pct_change(i)\n",
    "    \n",
    "    # cleaning up column names\n",
    "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "    df.rename(columns={'vol vol' : 'vol', 'mean_price mean_price' : 'mean_price'}, inplace=True)\n",
    "    \n",
    "    # filling times with no trades with previous prices\n",
    "    df['price open'].fillna(method='ffill', inplace=True)\n",
    "    df['price high'].fillna(method='ffill', inplace=True)\n",
    "    df['price low'].fillna(method='ffill', inplace=True)\n",
    "    df['price close'].fillna(method='ffill', inplace=True)\n",
    "    df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "    return df\n",
    "    \n",
    "def remove_closed(df):\n",
    "    # Removed closed hours\n",
    "    # dropping weekends\n",
    "    #https://stackoverflow.com/questions/37803040/remove-non-business-days-rows-from-pandas-dataframe\n",
    "    df = df[df.index.dayofweek<5] \n",
    "    # dropping Thanksgiving/Christmas\n",
    "    # https://stackoverflow.com/questions/3240458/how-to-increment-a-datetime-by-one-day\n",
    "    # https://stackoverflow.com/questions/41513324/python-pandas-drop-rows-of-a-timeserie-based-on-time-range\n",
    "    thanksgiving = pd.to_datetime('2019-11-28')\n",
    "    christmas = pd.to_datetime('2019-12-25')\n",
    "    tgdrop = pd.date_range(thanksgiving, thanksgiving+datetime.timedelta(days=1), freq='ms')\n",
    "    chrismasdrop = pd.date_range(christmas, christmas+datetime.timedelta(days=1), freq='ms')\n",
    "    df = df[~df.index.isin(tgdrop)]\n",
    "    df = df[~df.index.isin(chrismasdrop)]\n",
    "    \n",
    "    # Dropping hours not between 9:30am and 4pm\n",
    "    df.index = df.index.to_timestamp()\n",
    "    df = df.between_time('9:30', '16:00')\n",
    "    return df\n",
    "\n",
    "def get_data(directory, ind):\n",
    "    files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "    all_data = {}\n",
    "    for file in files:\n",
    "        df = pd.read_csv(directory + file)\n",
    "        df[ind] = pd.to_datetime(df[ind], \n",
    "                                         format='%Y-%m-%d %H:%M:%S')\n",
    "        df.set_index(ind, inplace=True)\n",
    "        df.index = pd.DatetimeIndex(df.index).to_period('ms')\n",
    "        df.sort_index(inplace=True)\n",
    "        try:\n",
    "            ticker = df['ticker'][0]\n",
    "        except:\n",
    "            ticker=df['company'][0]\n",
    "        all_data[ticker] = df\n",
    "#         print(f'loaded {ticker} from {file}')\n",
    "#         print(f'rows {df.shape[0]} imported')\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:21:24.691017Z",
     "start_time": "2020-06-04T19:19:47.611296Z"
    }
   },
   "outputs": [],
   "source": [
    "# stocks = get_data('./datasets/Russia Site/cleaned/', 'date_time')\n",
    "# twits = get_data('./datasets/twitters/withsent/', 'date')\n",
    "\n",
    "resampling_int = 's'\n",
    "span = 3600*18 #18 hours in seconds.  \n",
    "# 18 hours because the NYSE is closed for 17.5 from 4-9:30\n",
    "\n",
    "# for company in stocks.keys():\n",
    "#     process(stock[company], twits[company], 's')\n",
    "#     process(stock[company], twits[company], 'min')\n",
    "\n",
    "comps = ['csco']\n",
    "for company in comps: #stocks.keys()\n",
    "    # resample\n",
    "    stock = stocks[company].drop(columns=['date', 'time']).copy()\n",
    "    twit = twits[company][['vader_sentiment']].copy() # only care about this column\n",
    "    \n",
    "    stock['mean_price'] = stock['price']\n",
    "    stock = stock.resample(resampling_int).agg({'vol' : 'sum', 'price' : 'ohlc', 'mean_price' : 'mean'})\n",
    "    twit = twit.resample(resampling_int).mean()\n",
    "    \n",
    "    # ewm tweet score\n",
    "    twit['sent_mean'] = twit.ewm(span).mean() #weighed mean\n",
    "    twit.drop(columns='vader_sentiment', inplace=True)\n",
    "    # cleaning cols up before merge\n",
    "    stock.columns = [' '.join(col).strip() for col in stock.columns.values]\n",
    "    stock.rename(columns={'vol vol' : 'vol', 'mean_price mean_price' : 'mean_price'}, inplace=True)\n",
    "    \n",
    "    # Merge\n",
    "    df = pd.merge(stock, twit, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Removed closed hours\n",
    "    # dropping weekends\n",
    "    #https://stackoverflow.com/questions/37803040/remove-non-business-days-rows-from-pandas-dataframe\n",
    "    df = df[df.index.dayofweek<5] \n",
    "    # dropping Thanksgiving/Christmas\n",
    "    # https://stackoverflow.com/questions/3240458/how-to-increment-a-datetime-by-one-day\n",
    "    # https://stackoverflow.com/questions/41513324/python-pandas-drop-rows-of-a-timeserie-based-on-time-range\n",
    "    thanksgiving = pd.to_datetime('2019-11-28')\n",
    "    christmas = pd.to_datetime('2019-12-25')\n",
    "    tgdrop = pd.date_range(thanksgiving, thanksgiving+datetime.timedelta(days=1), freq='ms')\n",
    "    chrismasdrop = pd.date_range(christmas, christmas+datetime.timedelta(days=1), freq='ms')\n",
    "    df = df[~df.index.isin(tgdrop)]\n",
    "    df = df[~df.index.isin(chrismasdrop)]\n",
    "    \n",
    "    # Dropping hours not between 9:30am and 4pm\n",
    "    df.index = df.index.to_timestamp()\n",
    "    df = df.between_time('9:30', '16:00')\n",
    "     \n",
    "    # Fill NaNs and pct changes\n",
    "    # forward fill NAs in price\n",
    "    \n",
    "    df['price high'].fillna(method='ffill', inplace=True)\n",
    "    df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "    df['vol'].fillna(0, inplace=True)\n",
    "\n",
    "    intervals = [1, 2, 3, 4, 5, 10, 15, 30, 60]\n",
    "    for i in intervals:\n",
    "        df[f'high_px_{i}'] = df['price high'].pct_change(i)\n",
    "        df[f'mean_px_{i}'] = df['mean_price'].pct_change(i)\n",
    "    \n",
    "    df['price open'].fillna(method='ffill', inplace=True)\n",
    "    df['price high'].fillna(method='ffill', inplace=True)\n",
    "    df['price low'].fillna(method='ffill', inplace=True)\n",
    "    df['price close'].fillna(method='ffill', inplace=True)\n",
    "    df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "    # export\n",
    "    df['ticker'] = company\n",
    "    df.to_csv(f'./datasets/dow_clean/{company}.csv', index=True)\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:21:24.800151Z",
     "start_time": "2020-06-04T19:21:24.700555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol</th>\n",
       "      <th>price open</th>\n",
       "      <th>price high</th>\n",
       "      <th>price low</th>\n",
       "      <th>price close</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>sent_mean</th>\n",
       "      <th>high_px_1</th>\n",
       "      <th>mean_px_1</th>\n",
       "      <th>high_px_2</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_px_5</th>\n",
       "      <th>high_px_10</th>\n",
       "      <th>mean_px_10</th>\n",
       "      <th>high_px_15</th>\n",
       "      <th>mean_px_15</th>\n",
       "      <th>high_px_30</th>\n",
       "      <th>mean_px_30</th>\n",
       "      <th>high_px_60</th>\n",
       "      <th>mean_px_60</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-03 09:30:00</th>\n",
       "      <td>200</td>\n",
       "      <td>46.52</td>\n",
       "      <td>46.60</td>\n",
       "      <td>46.52</td>\n",
       "      <td>46.60</td>\n",
       "      <td>46.560</td>\n",
       "      <td>0.065705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>csco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-03 09:30:01</th>\n",
       "      <td>1100</td>\n",
       "      <td>46.58</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.57</td>\n",
       "      <td>46.59</td>\n",
       "      <td>46.590</td>\n",
       "      <td>0.065705</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>csco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-03 09:30:02</th>\n",
       "      <td>400</td>\n",
       "      <td>46.60</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.59</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.600</td>\n",
       "      <td>0.065705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>csco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-03 09:30:03</th>\n",
       "      <td>0</td>\n",
       "      <td>46.60</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.59</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.600</td>\n",
       "      <td>0.065705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>csco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-03 09:30:04</th>\n",
       "      <td>600</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.63</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.62</td>\n",
       "      <td>46.622</td>\n",
       "      <td>0.065705</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>csco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      vol  price open  price high  price low  price close  \\\n",
       "date_time                                                                   \n",
       "2019-09-03 09:30:00   200       46.52       46.60      46.52        46.60   \n",
       "2019-09-03 09:30:01  1100       46.58       46.62      46.57        46.59   \n",
       "2019-09-03 09:30:02   400       46.60       46.62      46.59        46.62   \n",
       "2019-09-03 09:30:03     0       46.60       46.62      46.59        46.62   \n",
       "2019-09-03 09:30:04   600       46.63       46.63      46.62        46.62   \n",
       "\n",
       "                     mean_price  sent_mean  high_px_1  mean_px_1  high_px_2  \\\n",
       "date_time                                                                     \n",
       "2019-09-03 09:30:00      46.560   0.065705        NaN        NaN        NaN   \n",
       "2019-09-03 09:30:01      46.590   0.065705   0.000429   0.000644        NaN   \n",
       "2019-09-03 09:30:02      46.600   0.065705   0.000000   0.000215   0.000429   \n",
       "2019-09-03 09:30:03      46.600   0.065705   0.000000   0.000000   0.000000   \n",
       "2019-09-03 09:30:04      46.622   0.065705   0.000215   0.000472   0.000215   \n",
       "\n",
       "                     ...  mean_px_5  high_px_10  mean_px_10  high_px_15  \\\n",
       "date_time            ...                                                  \n",
       "2019-09-03 09:30:00  ...        NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:01  ...        NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:02  ...        NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:03  ...        NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:04  ...        NaN         NaN         NaN         NaN   \n",
       "\n",
       "                     mean_px_15  high_px_30  mean_px_30  high_px_60  \\\n",
       "date_time                                                             \n",
       "2019-09-03 09:30:00         NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:01         NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:02         NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:03         NaN         NaN         NaN         NaN   \n",
       "2019-09-03 09:30:04         NaN         NaN         NaN         NaN   \n",
       "\n",
       "                     mean_px_60  ticker  \n",
       "date_time                                \n",
       "2019-09-03 09:30:00         NaN    csco  \n",
       "2019-09-03 09:30:01         NaN    csco  \n",
       "2019-09-03 09:30:02         NaN    csco  \n",
       "2019-09-03 09:30:03         NaN    csco  \n",
       "2019-09-03 09:30:04         NaN    csco  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:21:35.312523Z",
     "start_time": "2020-06-04T19:21:35.302454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vol', 'price open', 'price high', 'price low', 'price close',\n",
       "       'mean_price', 'sent_mean', 'high_px_1', 'mean_px_1', 'high_px_2',\n",
       "       'mean_px_2', 'high_px_3', 'mean_px_3', 'high_px_4', 'mean_px_4',\n",
       "       'high_px_5', 'mean_px_5', 'high_px_10', 'mean_px_10', 'high_px_15',\n",
       "       'mean_px_15', 'high_px_30', 'mean_px_30', 'high_px_60', 'mean_px_60',\n",
       "       'ticker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:41:59.824151Z",
     "start_time": "2020-06-03T21:41:59.237351Z"
    }
   },
   "outputs": [],
   "source": [
    "directory = './datasets/Russia Site/cleaned/'\n",
    "files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "stocks = {}\n",
    "for file in files:\n",
    "    df = pd.read_csv(directory + file)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], \n",
    "                                     format='%Y-%m-%d %H:%M:%S')\n",
    "    df.set_index('date_time', inplace=True)\n",
    "    df.index = pd.DatetimeIndex(df.index).to_period('ms')\n",
    "    df.sort_index(inplace=True)\n",
    "    ticker = df['ticker'][0]\n",
    "    stocks[ticker] = df\n",
    "#     print(f'loaded {ticker} from {file}')\n",
    "#     print(f'rows {df.shape[0]} imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:43:26.418017Z",
     "start_time": "2020-06-03T21:42:55.050925Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsf/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished exporting csco.  1/1\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for company, df_ in stocks.items():\n",
    "    df = df_.copy()\n",
    "    df.drop(columns=['date', 'time'], inplace=True)\n",
    "    \n",
    "    df['mean_price'] = df['price']\n",
    "    df=df.resample('s').agg({'vol' : 'sum', 'price' : 'ohlc', 'mean_price' : 'mean'})\n",
    "    # dropping weekends\n",
    "    #https://stackoverflow.com/questions/37803040/remove-non-business-days-rows-from-pandas-dataframe\n",
    "    df = df[df.index.dayofweek<5] \n",
    "    # dropping Thanksgiving/Christmas\n",
    "    # https://stackoverflow.com/questions/3240458/how-to-increment-a-datetime-by-one-day\n",
    "    # https://stackoverflow.com/questions/41513324/python-pandas-drop-rows-of-a-timeserie-based-on-time-range\n",
    "    thanksgiving = pd.to_datetime('2019-11-28')\n",
    "    christmas = pd.to_datetime('2019-12-25')\n",
    "    tgdrop = pd.date_range(thanksgiving, thanksgiving+datetime.timedelta(days=1), freq='ms')\n",
    "    chrismasdrop = pd.date_range(christmas, christmas+datetime.timedelta(days=1), freq='ms')\n",
    "    df = df[~df.index.isin(tgdrop)]\n",
    "    df = df[~df.index.isin(chrismasdrop)]\n",
    "    \n",
    "    # Dropping hours not between 9:30am and 4pm\n",
    "    df.index = df.index.to_timestamp()\n",
    "    df = df.between_time('9:30', '16:00')\n",
    "    \n",
    "    # forward fill NAs in price\n",
    "    df['price'].fillna(method='ffill', inplace=True)\n",
    "    df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "    df['vol'].fillna(0, inplace=True)\n",
    "\n",
    "    intervals = [1, 2, 3, 4, 5, 10, 15, 30, 60]\n",
    "    for i in intervals:\n",
    "        df[f'high_px_{i}'] = df['price']['high'].pct_change(i)\n",
    "        df[f'mean_px_{i}'] = df['mean_price'].pct_change(i)\n",
    "\n",
    "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "    df.rename(columns={'vol vol' : 'vol', 'mean_price mean_price' : 'mean_price'}, inplace=True)\n",
    "\n",
    "    df['price open'].fillna(method='ffill', inplace=True)\n",
    "    df['price high'].fillna(method='ffill', inplace=True)\n",
    "    df['price low'].fillna(method='ffill', inplace=True)\n",
    "    df['price close'].fillna(method='ffill', inplace=True)\n",
    "    df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    df['ticker'] = company\n",
    "    df.to_csv(f'./datasets/dow_clean/{company}.csv', index=True)\n",
    "    counter += 1\n",
    "    print(f'finished exporting {company}.  {counter}/{len(stocks.items())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-03T21:47:58.780159Z",
     "start_time": "2020-06-03T21:47:16.311239Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('./working.csv', index=True)\n",
    "\n",
    "df = stocks['csco'].iloc[:100].copy()\n",
    "company = 'csco'\n",
    "\n",
    "df.drop(columns=['date', 'time'], inplace=True)\n",
    "df['mean_price'] = df['price']\n",
    "df=df.resample('s').agg({'vol' : 'sum', 'price' : 'ohlc', 'mean_price' : 'mean'})\n",
    " # forward fill NAs in price\n",
    "df['price'].fillna(method='ffill', inplace=True)\n",
    "df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "df['vol'].fillna(0, inplace=True)\n",
    "\n",
    "intervals = [1, 2, 3, 4, 5, 10, 15, 30, 60]\n",
    "for i in intervals:\n",
    "    df[f'high_px_{i}'] = df['price']['high'].pct_change(i)\n",
    "    df[f'mean_px_{i}'] = df['mean_price'].pct_change(i)\n",
    "df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "df.rename(columns={'vol vol' : 'vol', 'mean_price mean_price' : 'mean_price'}, inplace=True)\n",
    "\n",
    "df['price open'].fillna(method='ffill', inplace=True)\n",
    "df['price high'].fillna(method='ffill', inplace=True)\n",
    "df['price low'].fillna(method='ffill', inplace=True)\n",
    "df['price close'].fillna(method='ffill', inplace=True)\n",
    "df['mean_price'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "df['ticker'] = company\n",
    "df.head()\n",
    "# df.to_csv(f'./{company}.csv', index=True)\n",
    "\n",
    "df = stocks['csco'].iloc[:100].copy()\n",
    "df.head()\n",
    "\n",
    "df.to_csv(f'./{company}.csv', index=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "df2 = pd.read_csv('./csco.csv', nrows=10, index_col='date_time', parse_dates=True)\n",
    "print(df2.index.dtype)\n",
    "df2.head()\n",
    "\n",
    "df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "df2.dtypes\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "df.rename(columns={'vol vol' : 'vol', 'mean_price mean_price' : 'mean_price'}, inplace=True)\n",
    "df.columns\n",
    "\n",
    "stocks['csco'].head()\n",
    "\n",
    "df2.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
